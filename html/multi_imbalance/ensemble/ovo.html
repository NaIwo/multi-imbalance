<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>multi_imbalance.ensemble.ovo API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>multi_imbalance.ensemble.ovo</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
from imblearn.over_sampling import SMOTE
from sklearn.base import BaseEstimator
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

from multi_imbalance.resampling.global_cs import GlobalCS


class OVO(BaseEstimator):
    &#34;&#34;&#34;

    OVO (One vs One) is an ensemble method that makes predictions for multi-class problems. OVO decomposes problem
    into m(m-1)/2 binary problems, where m is number of classes. Each of binary classifiers distinguishes between two
    classes. In the learning phase each classifier is learned only with instances from particular two classes. In
    prediction phase each classifier decides between these two classes. Results are aggregated and final output is
    derived depending on chosen aggregation model.

    &#34;&#34;&#34;

    _allowed_classifiers = [&#39;CART&#39;, &#39;NB&#39;, &#39;KNN&#39;]
    _allowed_voting_strategies = [&#39;max&#39;]
    _allowed_oversampling = [None, &#39;globalCS&#39;, &#39;SMOTE&#39;]
    _allowed_oversample_between = [&#39;all&#39;, &#39;maj-min&#39;]

    def __init__(self, voting_strategy=&#39;max&#39;, binary_classifier=&#39;CART&#39;, n_neighbors=5, oversample_binary=None,
                 oversample_between=&#39;all&#39;):
        &#34;&#34;&#34;
        Parameters
        ----------
        voting_strategy: aggregation model for deriving final output. Possible strategies:

        * &#39;max&#39;: class with largest number of votes is chosen,

        binary_classifier: binary classifier. Possible classifiers:

        * &#39;CART&#39;: Decision Tree Classifier,
        * &#39;KNN&#39;: K-Nearest Neighbors
        * &#39;NB&#39; : Naive Bayes

        n_neighbors: number of nearest neighbors in KNN, works only if binary_classifier==&#39;KNN&#39;

        oversample_between: types of classes between which oversampling should be applied. Possible values:
        * &#39;all&#39; - oversampling between each pair of classes
        * &#39;maj-min&#39; - oversampling only between majority ad minority classes

        &#34;&#34;&#34;
        self.voting_strategy = voting_strategy
        self.binary_classifier = binary_classifier
        self.n_neighbors = n_neighbors
        self.oversample_binary = oversample_binary
        self.oversample_between = oversample_between
        self._binary_classifiers = []
        self._labels = np.array([])
        self._minority_classes = list()

    def fit(self, X, y, minority_classes=None):
        &#34;&#34;&#34;
        Parameters
        ----------
        X: two dimensional numpy array (number of samples x number of features) with float numbers
        y: one dimensional numpy array with labels for rows in X
        minority_classes: list of classes considered to be minority

        Returns
        -------
        self: object
        &#34;&#34;&#34;
        if minority_classes is None:
            minority_classes = list()

        self._labels = np.unique(y)
        self._minority_classes = minority_classes
        num_of_classes = len(self._labels)
        self._binary_classifiers = [[self._get_classifier() for _ in range(n)] for n in
                                    range(0, num_of_classes)]
        self._learn_binary_classifiers(X, y)
        return self

    def predict(self, X):
        &#34;&#34;&#34;
        Parameters
        ----------
        X: two dimensional numpy array (number of samples x number of features) with float numbers

        Returns
        -------
        y : numpy array, shape = [number of samples]
            Predicted target values for X.
        &#34;&#34;&#34;
        num_of_classes = len(self._labels)
        predicted = list()
        for instance in X:
            binary_outputs_matrix = self._construct_binary_outputs_matrix(instance, num_of_classes)
            predicted.append(self._perform_voting(binary_outputs_matrix))

        return np.array(predicted)

    def _construct_binary_outputs_matrix(self, instance, num_of_classes):
        binary_outputs_matrix = np.zeros((num_of_classes, num_of_classes))
        for class_idx1 in range(len(self._labels)):
            for class_idx2 in range(class_idx1):
                binary_outputs_matrix[class_idx1][class_idx2] = self._binary_classifiers[class_idx1][class_idx2] \
                    .predict([instance])
        return binary_outputs_matrix

    def _learn_binary_classifiers(self, X, y):
        for row in range(len(self._labels)):
            for col in range(row):
                first_class, second_class = self._labels[row], self._labels[col]
                filtered_indices = [idx for idx in range(len(y)) if y[idx] in (first_class, second_class)]
                X_filtered, y_filtered = X[filtered_indices], y[filtered_indices]
                if self.should_perform_oversampling(first_class, second_class):
                    X_filtered, y_filtered = self._oversample(X_filtered, y_filtered, strategy=self.oversample_binary)
                self._binary_classifiers[row][col].fit(X_filtered, y_filtered)

    def _get_classifier(self):
        if self.binary_classifier not in OVO._allowed_classifiers:
            raise ValueError(&#34;Unknown binary classifier: %s, expected to be one of %s.&#34;
                             % (self.binary_classifier, OVO._allowed_classifiers))
        elif self.binary_classifier == &#39;CART&#39;:
            decision_tree_classifier = DecisionTreeClassifier()
            return decision_tree_classifier
        elif self.binary_classifier == &#39;NB&#39;:
            gnb = GaussianNB()
            return gnb
        elif self.binary_classifier == &#39;KNN&#39;:
            knn = KNeighborsClassifier(n_neighbors=self.n_neighbors)
            return knn

    def _perform_voting(self, binary_outputs_matrix):
        if self.voting_strategy not in OVO._allowed_voting_strategies:
            raise ValueError(&#34;Unknown voting strategy: %s, expected to be one of %s.&#34;
                             % (self.voting_strategy, OVO._allowed_voting_strategies))
        elif self.voting_strategy == &#39;max&#39;:
            return self._perform_max_voting(binary_outputs_matrix)

    def _perform_max_voting(self, binary_outputs_matrix):
        scores = np.zeros(len(self._labels))
        for clf_1 in range(len(binary_outputs_matrix)):
            for clf_2 in range(clf_1):
                scores[self._labels.tolist().index(binary_outputs_matrix[clf_1][clf_2])] += 1
        return self._labels[np.argmax(scores)]

    def _oversample(self, X, y, strategy=None):
        if strategy not in OVO._allowed_oversampling:
            raise ValueError(&#34;Unknown matrix generation encoding: %s, expected to be one of %s.&#34;
                             % (strategy, OVO._allowed_oversampling))
        elif strategy is None:
            return X, y
        elif strategy == &#39;globalCS&#39;:
            gcs = GlobalCS()
            return gcs.fit_transform(X, y)
        elif strategy == &#39;SMOTE&#39;:
            return self._smote_oversample_if_possible_random_otherwise(X, y)

    def _smote_oversample_if_possible_random_otherwise(self, X, y):
        if min(np.unique(y, return_counts=True)[1]) &lt; 2:
            return GlobalCS().fit_transform(X, y)

        n_neighbors = 3 if min(np.unique(y, return_counts=True)[1]) &gt; 3 else 1
        smote = SMOTE(k_neighbors=n_neighbors)
        smote.fit(X, y)
        return smote.fit_resample(X, y)

    def should_perform_oversampling(self, first_class, second_class):
        if self.oversample_between not in OVO._allowed_oversample_between:
            raise ValueError(&#34;Unknown strategy for oversampling: %s, expected to be one of %s.&#34;
                             % (self.oversample_between, OVO._allowed_oversample_between))
        elif self.oversample_between == &#39;all&#39;:
            return True
        elif self.oversample_between == &#39;maj-min&#39;:
            return (first_class in self._minority_classes and second_class not in self._minority_classes) or \
                   (second_class in self._minority_classes and first_class not in self._minority_classes)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="multi_imbalance.ensemble.ovo.OVO"><code class="flex name class">
<span>class <span class="ident">OVO</span></span>
<span>(</span><span>voting_strategy='max', binary_classifier='CART', n_neighbors=5, oversample_binary=None, oversample_between='all')</span>
</code></dt>
<dd>
<section class="desc"><p>OVO (One vs One) is an ensemble method that makes predictions for multi-class problems. OVO decomposes problem
into m(m-1)/2 binary problems, where m is number of classes. Each of binary classifiers distinguishes between two
classes. In the learning phase each classifier is learned only with instances from particular two classes. In
prediction phase each classifier decides between these two classes. Results are aggregated and final output is
derived depending on chosen aggregation model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>voting_strategy</code></strong> :&ensp;<code>aggregation</code> <code>model</code> <code>for</code> <code>deriving</code> <code>final</code> <code>output.</code> <code>Possible</code> <code>strategies</code>:</dt>
<dd>&nbsp;</dd>
</dl>
<ul>
<li>'max': class with largest number of votes is chosen,</li>
</ul>
<dl>
<dt><strong><code>binary_classifier</code></strong> :&ensp;<code>binary</code> <code>classifier.</code> <code>Possible</code> <code>classifiers</code>:</dt>
<dd>&nbsp;</dd>
</dl>
<ul>
<li>'CART': Decision Tree Classifier,</li>
<li>'KNN': K-Nearest Neighbors</li>
<li>'NB' : Naive Bayes</li>
</ul>
<dl>
<dt><strong><code>n_neighbors</code></strong> :&ensp;<code>number</code> of <code>nearest</code> <code>neighbors</code> <code>in</code> <code>KNN</code>, <code>works</code> <code>only</code> <code>if</code> <code>binary_classifier</code>==<code>'KNN'</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>oversample_between</code></strong> :&ensp;<code>types</code> of <code>classes</code> <code>between</code> <code>which</code> <code>oversampling</code> <code>should</code> <code>be</code> <code>applied.</code> <code>Possible</code> <code>values</code>:</dt>
<dd>&nbsp;</dd>
</dl>
<ul>
<li>'all' - oversampling between each pair of classes</li>
<li>'maj-min' - oversampling only between majority ad minority classes</li>
</ul></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OVO(BaseEstimator):
    &#34;&#34;&#34;

    OVO (One vs One) is an ensemble method that makes predictions for multi-class problems. OVO decomposes problem
    into m(m-1)/2 binary problems, where m is number of classes. Each of binary classifiers distinguishes between two
    classes. In the learning phase each classifier is learned only with instances from particular two classes. In
    prediction phase each classifier decides between these two classes. Results are aggregated and final output is
    derived depending on chosen aggregation model.

    &#34;&#34;&#34;

    _allowed_classifiers = [&#39;CART&#39;, &#39;NB&#39;, &#39;KNN&#39;]
    _allowed_voting_strategies = [&#39;max&#39;]
    _allowed_oversampling = [None, &#39;globalCS&#39;, &#39;SMOTE&#39;]
    _allowed_oversample_between = [&#39;all&#39;, &#39;maj-min&#39;]

    def __init__(self, voting_strategy=&#39;max&#39;, binary_classifier=&#39;CART&#39;, n_neighbors=5, oversample_binary=None,
                 oversample_between=&#39;all&#39;):
        &#34;&#34;&#34;
        Parameters
        ----------
        voting_strategy: aggregation model for deriving final output. Possible strategies:

        * &#39;max&#39;: class with largest number of votes is chosen,

        binary_classifier: binary classifier. Possible classifiers:

        * &#39;CART&#39;: Decision Tree Classifier,
        * &#39;KNN&#39;: K-Nearest Neighbors
        * &#39;NB&#39; : Naive Bayes

        n_neighbors: number of nearest neighbors in KNN, works only if binary_classifier==&#39;KNN&#39;

        oversample_between: types of classes between which oversampling should be applied. Possible values:
        * &#39;all&#39; - oversampling between each pair of classes
        * &#39;maj-min&#39; - oversampling only between majority ad minority classes

        &#34;&#34;&#34;
        self.voting_strategy = voting_strategy
        self.binary_classifier = binary_classifier
        self.n_neighbors = n_neighbors
        self.oversample_binary = oversample_binary
        self.oversample_between = oversample_between
        self._binary_classifiers = []
        self._labels = np.array([])
        self._minority_classes = list()

    def fit(self, X, y, minority_classes=None):
        &#34;&#34;&#34;
        Parameters
        ----------
        X: two dimensional numpy array (number of samples x number of features) with float numbers
        y: one dimensional numpy array with labels for rows in X
        minority_classes: list of classes considered to be minority

        Returns
        -------
        self: object
        &#34;&#34;&#34;
        if minority_classes is None:
            minority_classes = list()

        self._labels = np.unique(y)
        self._minority_classes = minority_classes
        num_of_classes = len(self._labels)
        self._binary_classifiers = [[self._get_classifier() for _ in range(n)] for n in
                                    range(0, num_of_classes)]
        self._learn_binary_classifiers(X, y)
        return self

    def predict(self, X):
        &#34;&#34;&#34;
        Parameters
        ----------
        X: two dimensional numpy array (number of samples x number of features) with float numbers

        Returns
        -------
        y : numpy array, shape = [number of samples]
            Predicted target values for X.
        &#34;&#34;&#34;
        num_of_classes = len(self._labels)
        predicted = list()
        for instance in X:
            binary_outputs_matrix = self._construct_binary_outputs_matrix(instance, num_of_classes)
            predicted.append(self._perform_voting(binary_outputs_matrix))

        return np.array(predicted)

    def _construct_binary_outputs_matrix(self, instance, num_of_classes):
        binary_outputs_matrix = np.zeros((num_of_classes, num_of_classes))
        for class_idx1 in range(len(self._labels)):
            for class_idx2 in range(class_idx1):
                binary_outputs_matrix[class_idx1][class_idx2] = self._binary_classifiers[class_idx1][class_idx2] \
                    .predict([instance])
        return binary_outputs_matrix

    def _learn_binary_classifiers(self, X, y):
        for row in range(len(self._labels)):
            for col in range(row):
                first_class, second_class = self._labels[row], self._labels[col]
                filtered_indices = [idx for idx in range(len(y)) if y[idx] in (first_class, second_class)]
                X_filtered, y_filtered = X[filtered_indices], y[filtered_indices]
                if self.should_perform_oversampling(first_class, second_class):
                    X_filtered, y_filtered = self._oversample(X_filtered, y_filtered, strategy=self.oversample_binary)
                self._binary_classifiers[row][col].fit(X_filtered, y_filtered)

    def _get_classifier(self):
        if self.binary_classifier not in OVO._allowed_classifiers:
            raise ValueError(&#34;Unknown binary classifier: %s, expected to be one of %s.&#34;
                             % (self.binary_classifier, OVO._allowed_classifiers))
        elif self.binary_classifier == &#39;CART&#39;:
            decision_tree_classifier = DecisionTreeClassifier()
            return decision_tree_classifier
        elif self.binary_classifier == &#39;NB&#39;:
            gnb = GaussianNB()
            return gnb
        elif self.binary_classifier == &#39;KNN&#39;:
            knn = KNeighborsClassifier(n_neighbors=self.n_neighbors)
            return knn

    def _perform_voting(self, binary_outputs_matrix):
        if self.voting_strategy not in OVO._allowed_voting_strategies:
            raise ValueError(&#34;Unknown voting strategy: %s, expected to be one of %s.&#34;
                             % (self.voting_strategy, OVO._allowed_voting_strategies))
        elif self.voting_strategy == &#39;max&#39;:
            return self._perform_max_voting(binary_outputs_matrix)

    def _perform_max_voting(self, binary_outputs_matrix):
        scores = np.zeros(len(self._labels))
        for clf_1 in range(len(binary_outputs_matrix)):
            for clf_2 in range(clf_1):
                scores[self._labels.tolist().index(binary_outputs_matrix[clf_1][clf_2])] += 1
        return self._labels[np.argmax(scores)]

    def _oversample(self, X, y, strategy=None):
        if strategy not in OVO._allowed_oversampling:
            raise ValueError(&#34;Unknown matrix generation encoding: %s, expected to be one of %s.&#34;
                             % (strategy, OVO._allowed_oversampling))
        elif strategy is None:
            return X, y
        elif strategy == &#39;globalCS&#39;:
            gcs = GlobalCS()
            return gcs.fit_transform(X, y)
        elif strategy == &#39;SMOTE&#39;:
            return self._smote_oversample_if_possible_random_otherwise(X, y)

    def _smote_oversample_if_possible_random_otherwise(self, X, y):
        if min(np.unique(y, return_counts=True)[1]) &lt; 2:
            return GlobalCS().fit_transform(X, y)

        n_neighbors = 3 if min(np.unique(y, return_counts=True)[1]) &gt; 3 else 1
        smote = SMOTE(k_neighbors=n_neighbors)
        smote.fit(X, y)
        return smote.fit_resample(X, y)

    def should_perform_oversampling(self, first_class, second_class):
        if self.oversample_between not in OVO._allowed_oversample_between:
            raise ValueError(&#34;Unknown strategy for oversampling: %s, expected to be one of %s.&#34;
                             % (self.oversample_between, OVO._allowed_oversample_between))
        elif self.oversample_between == &#39;all&#39;:
            return True
        elif self.oversample_between == &#39;maj-min&#39;:
            return (first_class in self._minority_classes and second_class not in self._minority_classes) or \
                   (second_class in self._minority_classes and first_class not in self._minority_classes)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="multi_imbalance.ensemble.ovo.OVO.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y, minority_classes=None)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>two</code> <code>dimensional</code> <code>numpy</code> <code>array</code> (<code>number</code> of <code>samples</code> <code>x</code> <code>number</code> of <code>features</code>) <code>with</code> <code>float</code> <code>numbers</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>one</code> <code>dimensional</code> <code>numpy</code> <code>array</code> <code>with</code> <code>labels</code> <code>for</code> <code>rows</code> <code>in</code> <code>X</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>minority_classes</code></strong> :&ensp;<code>list</code> of <code>classes</code> <code>considered</code> <code>to</code> <code>be</code> <code>minority</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X, y, minority_classes=None):
    &#34;&#34;&#34;
    Parameters
    ----------
    X: two dimensional numpy array (number of samples x number of features) with float numbers
    y: one dimensional numpy array with labels for rows in X
    minority_classes: list of classes considered to be minority

    Returns
    -------
    self: object
    &#34;&#34;&#34;
    if minority_classes is None:
        minority_classes = list()

    self._labels = np.unique(y)
    self._minority_classes = minority_classes
    num_of_classes = len(self._labels)
    self._binary_classifiers = [[self._get_classifier() for _ in range(n)] for n in
                                range(0, num_of_classes)]
    self._learn_binary_classifiers(X, y)
    return self</code></pre>
</details>
</dd>
<dt id="multi_imbalance.ensemble.ovo.OVO.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>two</code> <code>dimensional</code> <code>numpy</code> <code>array</code> (<code>number</code> of <code>samples</code> <code>x</code> <code>number</code> of <code>features</code>) <code>with</code> <code>float</code> <code>numbers</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>numpy</code> <code>array</code>, <code>shape</code> = [<code>number</code> of <code>samples</code>]</dt>
<dd>Predicted target values for X.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, X):
    &#34;&#34;&#34;
    Parameters
    ----------
    X: two dimensional numpy array (number of samples x number of features) with float numbers

    Returns
    -------
    y : numpy array, shape = [number of samples]
        Predicted target values for X.
    &#34;&#34;&#34;
    num_of_classes = len(self._labels)
    predicted = list()
    for instance in X:
        binary_outputs_matrix = self._construct_binary_outputs_matrix(instance, num_of_classes)
        predicted.append(self._perform_voting(binary_outputs_matrix))

    return np.array(predicted)</code></pre>
</details>
</dd>
<dt id="multi_imbalance.ensemble.ovo.OVO.should_perform_oversampling"><code class="name flex">
<span>def <span class="ident">should_perform_oversampling</span></span>(<span>self, first_class, second_class)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def should_perform_oversampling(self, first_class, second_class):
    if self.oversample_between not in OVO._allowed_oversample_between:
        raise ValueError(&#34;Unknown strategy for oversampling: %s, expected to be one of %s.&#34;
                         % (self.oversample_between, OVO._allowed_oversample_between))
    elif self.oversample_between == &#39;all&#39;:
        return True
    elif self.oversample_between == &#39;maj-min&#39;:
        return (first_class in self._minority_classes and second_class not in self._minority_classes) or \
               (second_class in self._minority_classes and first_class not in self._minority_classes)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="multi_imbalance.ensemble" href="index.html">multi_imbalance.ensemble</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="multi_imbalance.ensemble.ovo.OVO" href="#multi_imbalance.ensemble.ovo.OVO">OVO</a></code></h4>
<ul class="">
<li><code><a title="multi_imbalance.ensemble.ovo.OVO.fit" href="#multi_imbalance.ensemble.ovo.OVO.fit">fit</a></code></li>
<li><code><a title="multi_imbalance.ensemble.ovo.OVO.predict" href="#multi_imbalance.ensemble.ovo.OVO.predict">predict</a></code></li>
<li><code><a title="multi_imbalance.ensemble.ovo.OVO.should_perform_oversampling" href="#multi_imbalance.ensemble.ovo.OVO.should_perform_oversampling">should_perform_oversampling</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>