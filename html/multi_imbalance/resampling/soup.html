<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>multi_imbalance.resampling.soup API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>multi_imbalance.resampling.soup</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from collections import Counter, defaultdict
from copy import deepcopy
from operator import itemgetter

import numpy as np
import sklearn
from sklearn.base import TransformerMixin
from sklearn.neighbors import NearestNeighbors


class SOUP(TransformerMixin):
    &#34;&#34;&#34;
    Similarity Oversampling and Undersampling Preprocessing (SOUP) is an algorithm that equalizes number of samples
    in each class. It also takes care of the similarity between classes, which means that it removes samples from
    majority class, that are close to samples from the other class and duplicate samples from the minority classes,
    which are in the safest area in space
    &#34;&#34;&#34;

    def __init__(self, k: int = 7) -&gt; None:
        self.k = k
        self.quantities, self.goal_quantity = [None] * 2

    def fit_transform(self, _X, _y, **fit_params):
        &#34;&#34;&#34;

        Parameters
        ----------
        X two dimensional numpy array (number of samples x number of features) with float numbers
        y one dimensional numpy array with labels for rows in X
        maj_int_min dict {&#39;maj&#39;: majority class labels, &#39;min&#39;: minority class labels}

        Returns
        -------
        Resampled X (mean class quantity * number of unique classes), y (number of rows in X) as numpy array
        &#34;&#34;&#34;

        X = deepcopy(_X)
        y = deepcopy(_y)

        assert len(X.shape) == 2, &#39;X should have 2 dimension&#39;
        assert X.shape[0] == y.shape[0], &#39;Number of labels must be equal to number of samples&#39;

        self.quantities = Counter(y)
        maj_int_min = fit_params.get(&#39;maj_int_min&#39;)
        self.goal_quantity = self._calculate_goal_quantity(maj_int_min)
        dsc_maj_cls = sorted(((v, i) for v, i in self.quantities.items() if i &gt;= self.goal_quantity), key=itemgetter(1),
                             reverse=True)
        asc_min_cls = sorted(((v, i) for v, i in self.quantities.items() if i &lt; self.goal_quantity), key=itemgetter(1),
                             reverse=False)

        for class_name, class_quantity in dsc_maj_cls:
            X, y = self._undersample(X, y, class_name)

        for class_name, class_quantity in asc_min_cls:
            X, y = self._oversample(X, y, class_name)

        if fit_params.get(&#39;shuffle&#39;):
            X, y = sklearn.utils.shuffle(X, y)

        return np.array(X), np.array(y)

    def _construct_class_safe_levels(self, X, y, class_name) -&gt; defaultdict:
        self.quantities = Counter(y)
        indices_in_class = [i for i, value in enumerate(y) if value == class_name]

        neigh_clf = NearestNeighbors(n_neighbors=self.k + 1).fit(X)
        neighbour_indices = neigh_clf.kneighbors(X[indices_in_class], return_distance=False)[:, 1:]
        neighbour_classes = y[neighbour_indices]

        class_safe_levels = defaultdict(float)
        for i, sample_id in enumerate(indices_in_class):
            neighbours_quantities = Counter(neighbour_classes[i])
            class_safe_levels[sample_id] = self._calculate_sample_safe_level(class_name, neighbours_quantities)

        return class_safe_levels

    def _calculate_sample_safe_level(self, class_name, neighbours_quantities: Counter):
        safe_level = 0
        q: Counter = self.quantities

        for neigh_label, neigh_q in neighbours_quantities.items():
            similarity_between_classes = min(q[class_name], q[neigh_label]) / max(q[class_name], q[neigh_label])
            safe_level += neigh_q * similarity_between_classes

        safe_level /= self.k

        if safe_level &gt; 1:
            raise ValueError(f&#39;Safe level is bigger than 1: {safe_level}&#39;)

        return safe_level

    def _undersample(self, X, y, class_name):
        safe_levels_of_samples_in_class = self._construct_class_safe_levels(X, y, class_name)

        class_quantity = self.quantities[class_name]
        safe_levels_list = sorted(safe_levels_of_samples_in_class.items(), key=itemgetter(1))
        samples_to_remove_quantity = max(0, int(class_quantity - self.goal_quantity))
        if samples_to_remove_quantity &gt; 0:
            remove_indices = list(map(itemgetter(0), safe_levels_list[:samples_to_remove_quantity]))
            X = np.delete(X, remove_indices, axis=0)
            y = np.delete(y, remove_indices, axis=0)

        return X, y

    def _oversample(self, X, y, class_name):
        safe_levels_of_samples_in_class = self._construct_class_safe_levels(X, y, class_name)
        class_quantity = self.quantities[class_name]
        safe_levels_list = list(sorted(safe_levels_of_samples_in_class.items(), key=itemgetter(1), reverse=True))

        difference = self.goal_quantity - class_quantity
        while difference &gt; 0:
            quantity_items_to_copy = min(difference, class_quantity)
            indices_to_copy = list(map(itemgetter(0), safe_levels_list[:quantity_items_to_copy]))
            X = np.vstack((X, X[indices_to_copy]))
            y = np.hstack((y, y[indices_to_copy]))
            difference -= quantity_items_to_copy

        return X, y

    def _calculate_goal_quantity(self, maj_int_min=None):
        if maj_int_min is None:
            maj_q = max(list(self.quantities.values()))
            min_q = min(list(self.quantities.values()))
        else:
            maj_classes = {k: v for k, v in self.quantities.items() if k in maj_int_min[&#39;maj&#39;]}
            maj_q = min(list(maj_classes.values()))
            min_classes = {k: v for k, v in self.quantities.items() if k in maj_int_min[&#39;min&#39;]}
            min_q = max(list(min_classes.values()))
        return np.mean((min_q, maj_q), dtype=int)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="multi_imbalance.resampling.soup.SOUP"><code class="flex name class">
<span>class <span class="ident">SOUP</span></span>
<span>(</span><span>k=7)</span>
</code></dt>
<dd>
<section class="desc"><p>Similarity Oversampling and Undersampling Preprocessing (SOUP) is an algorithm that equalizes number of samples
in each class. It also takes care of the similarity between classes, which means that it removes samples from
majority class, that are close to samples from the other class and duplicate samples from the minority classes,
which are in the safest area in space</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SOUP(TransformerMixin):
    &#34;&#34;&#34;
    Similarity Oversampling and Undersampling Preprocessing (SOUP) is an algorithm that equalizes number of samples
    in each class. It also takes care of the similarity between classes, which means that it removes samples from
    majority class, that are close to samples from the other class and duplicate samples from the minority classes,
    which are in the safest area in space
    &#34;&#34;&#34;

    def __init__(self, k: int = 7) -&gt; None:
        self.k = k
        self.quantities, self.goal_quantity = [None] * 2

    def fit_transform(self, _X, _y, **fit_params):
        &#34;&#34;&#34;

        Parameters
        ----------
        X two dimensional numpy array (number of samples x number of features) with float numbers
        y one dimensional numpy array with labels for rows in X
        maj_int_min dict {&#39;maj&#39;: majority class labels, &#39;min&#39;: minority class labels}

        Returns
        -------
        Resampled X (mean class quantity * number of unique classes), y (number of rows in X) as numpy array
        &#34;&#34;&#34;

        X = deepcopy(_X)
        y = deepcopy(_y)

        assert len(X.shape) == 2, &#39;X should have 2 dimension&#39;
        assert X.shape[0] == y.shape[0], &#39;Number of labels must be equal to number of samples&#39;

        self.quantities = Counter(y)
        maj_int_min = fit_params.get(&#39;maj_int_min&#39;)
        self.goal_quantity = self._calculate_goal_quantity(maj_int_min)
        dsc_maj_cls = sorted(((v, i) for v, i in self.quantities.items() if i &gt;= self.goal_quantity), key=itemgetter(1),
                             reverse=True)
        asc_min_cls = sorted(((v, i) for v, i in self.quantities.items() if i &lt; self.goal_quantity), key=itemgetter(1),
                             reverse=False)

        for class_name, class_quantity in dsc_maj_cls:
            X, y = self._undersample(X, y, class_name)

        for class_name, class_quantity in asc_min_cls:
            X, y = self._oversample(X, y, class_name)

        if fit_params.get(&#39;shuffle&#39;):
            X, y = sklearn.utils.shuffle(X, y)

        return np.array(X), np.array(y)

    def _construct_class_safe_levels(self, X, y, class_name) -&gt; defaultdict:
        self.quantities = Counter(y)
        indices_in_class = [i for i, value in enumerate(y) if value == class_name]

        neigh_clf = NearestNeighbors(n_neighbors=self.k + 1).fit(X)
        neighbour_indices = neigh_clf.kneighbors(X[indices_in_class], return_distance=False)[:, 1:]
        neighbour_classes = y[neighbour_indices]

        class_safe_levels = defaultdict(float)
        for i, sample_id in enumerate(indices_in_class):
            neighbours_quantities = Counter(neighbour_classes[i])
            class_safe_levels[sample_id] = self._calculate_sample_safe_level(class_name, neighbours_quantities)

        return class_safe_levels

    def _calculate_sample_safe_level(self, class_name, neighbours_quantities: Counter):
        safe_level = 0
        q: Counter = self.quantities

        for neigh_label, neigh_q in neighbours_quantities.items():
            similarity_between_classes = min(q[class_name], q[neigh_label]) / max(q[class_name], q[neigh_label])
            safe_level += neigh_q * similarity_between_classes

        safe_level /= self.k

        if safe_level &gt; 1:
            raise ValueError(f&#39;Safe level is bigger than 1: {safe_level}&#39;)

        return safe_level

    def _undersample(self, X, y, class_name):
        safe_levels_of_samples_in_class = self._construct_class_safe_levels(X, y, class_name)

        class_quantity = self.quantities[class_name]
        safe_levels_list = sorted(safe_levels_of_samples_in_class.items(), key=itemgetter(1))
        samples_to_remove_quantity = max(0, int(class_quantity - self.goal_quantity))
        if samples_to_remove_quantity &gt; 0:
            remove_indices = list(map(itemgetter(0), safe_levels_list[:samples_to_remove_quantity]))
            X = np.delete(X, remove_indices, axis=0)
            y = np.delete(y, remove_indices, axis=0)

        return X, y

    def _oversample(self, X, y, class_name):
        safe_levels_of_samples_in_class = self._construct_class_safe_levels(X, y, class_name)
        class_quantity = self.quantities[class_name]
        safe_levels_list = list(sorted(safe_levels_of_samples_in_class.items(), key=itemgetter(1), reverse=True))

        difference = self.goal_quantity - class_quantity
        while difference &gt; 0:
            quantity_items_to_copy = min(difference, class_quantity)
            indices_to_copy = list(map(itemgetter(0), safe_levels_list[:quantity_items_to_copy]))
            X = np.vstack((X, X[indices_to_copy]))
            y = np.hstack((y, y[indices_to_copy]))
            difference -= quantity_items_to_copy

        return X, y

    def _calculate_goal_quantity(self, maj_int_min=None):
        if maj_int_min is None:
            maj_q = max(list(self.quantities.values()))
            min_q = min(list(self.quantities.values()))
        else:
            maj_classes = {k: v for k, v in self.quantities.items() if k in maj_int_min[&#39;maj&#39;]}
            maj_q = min(list(maj_classes.values()))
            min_classes = {k: v for k, v in self.quantities.items() if k in maj_int_min[&#39;min&#39;]}
            min_q = max(list(min_classes.values()))
        return np.mean((min_q, maj_q), dtype=int)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.TransformerMixin</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="multi_imbalance.resampling.soup.SOUP.fit_transform"><code class="name flex">
<span>def <span class="ident">fit_transform</span></span>(<span>self, _X, _y, **fit_params)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="parameters">Parameters</h2>
<p>X two dimensional numpy array (number of samples x number of features) with float numbers
y one dimensional numpy array with labels for rows in X
maj_int_min dict {'maj': majority class labels, 'min': minority class labels}</p>
<h2 id="returns">Returns</h2>
<p>Resampled X (mean class quantity * number of unique classes), y (number of rows in X) as numpy array</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_transform(self, _X, _y, **fit_params):
    &#34;&#34;&#34;

    Parameters
    ----------
    X two dimensional numpy array (number of samples x number of features) with float numbers
    y one dimensional numpy array with labels for rows in X
    maj_int_min dict {&#39;maj&#39;: majority class labels, &#39;min&#39;: minority class labels}

    Returns
    -------
    Resampled X (mean class quantity * number of unique classes), y (number of rows in X) as numpy array
    &#34;&#34;&#34;

    X = deepcopy(_X)
    y = deepcopy(_y)

    assert len(X.shape) == 2, &#39;X should have 2 dimension&#39;
    assert X.shape[0] == y.shape[0], &#39;Number of labels must be equal to number of samples&#39;

    self.quantities = Counter(y)
    maj_int_min = fit_params.get(&#39;maj_int_min&#39;)
    self.goal_quantity = self._calculate_goal_quantity(maj_int_min)
    dsc_maj_cls = sorted(((v, i) for v, i in self.quantities.items() if i &gt;= self.goal_quantity), key=itemgetter(1),
                         reverse=True)
    asc_min_cls = sorted(((v, i) for v, i in self.quantities.items() if i &lt; self.goal_quantity), key=itemgetter(1),
                         reverse=False)

    for class_name, class_quantity in dsc_maj_cls:
        X, y = self._undersample(X, y, class_name)

    for class_name, class_quantity in asc_min_cls:
        X, y = self._oversample(X, y, class_name)

    if fit_params.get(&#39;shuffle&#39;):
        X, y = sklearn.utils.shuffle(X, y)

    return np.array(X), np.array(y)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="multi_imbalance.resampling" href="index.html">multi_imbalance.resampling</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="multi_imbalance.resampling.soup.SOUP" href="#multi_imbalance.resampling.soup.SOUP">SOUP</a></code></h4>
<ul class="">
<li><code><a title="multi_imbalance.resampling.soup.SOUP.fit_transform" href="#multi_imbalance.resampling.soup.SOUP.fit_transform">fit_transform</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>