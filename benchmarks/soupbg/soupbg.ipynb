{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "from IPython.core.display import display\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from multi_imbalance.ensemble.SOUPBagging import SOUPBagging\n",
    "from multi_imbalance.resampling.SOUP import SOUP\n",
    "from multi_imbalance.resampling.MDO import MDO\n",
    "from multi_imbalance.resampling.GlobalCS import GlobalCS\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from multi_imbalance.resampling.spider import SPIDER3\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "import logging\n",
    "from multi_imbalance.utils.data import load_arff_datasets\n",
    "from multi_imbalance.utils.min_int_maj import maj_int_min\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def green_valid_backgroud(s):\n",
    "#     correct = ['1czysty-cut', '2delikatne-cut', '3mocniej-cut','4delikatne-bezover-cut', 'cmc', 'dermatology', 'new_ecoli','new_vehicle','thyroid-newthyroid']\n",
    "#     return ['background-color: green' if v in correct else '' for v in list(s.index)]\n",
    "# \n",
    "\n",
    "\n",
    "def bold_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "    \n",
    "def print_scores(scores, only_read_dt = False):\n",
    "    display(\"G-MEAN\")\n",
    "    df = pd.DataFrame(scores).T\n",
    "    if only_read_dt:\n",
    "        df = df.iloc[4:]\n",
    "    df2 = df.style.apply(bold_max, axis=1)\n",
    "    display(df2)\n",
    "\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    display(pd.DataFrame(df.mean().sort_values(ascending=False),columns=['Mean G-mean']))\n",
    "    display(pd.DataFrame(df.rank(axis=1,ascending=False).mean().sort_values(),columns=['Mean rank']))\n",
    "# print_scores(scores_knn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def resample_data(resample, seed, X_train, y_train, no_classes, dataset_name):\n",
    "    if resample == 'base':\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    elif resample=='soup':\n",
    "        soup = SOUP(k=3)\n",
    "        X_train_resampled, y_train_resampled = soup.fit_transform(np.copy(X_train), np.copy(y_train))\n",
    "    elif resample=='global':\n",
    "        global_cs = GlobalCS()\n",
    "        X_train_resampled, y_train_resampled = global_cs.fit_transform(np.copy(X_train), np.copy(y_train), shuffle=False)\n",
    "    elif resample=='smote':\n",
    "        smote = SMOTE(random_state=seed)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_sample(np.copy(X_train), np.copy(y_train))\n",
    "    elif resample=='mdo':\n",
    "        mdo = MDO(k=3, k1_frac=0.5, seed=seed)\n",
    "        X_train_resampled, y_train_resampled = mdo.fit_transform(np.copy(X_train), np.copy(y_train), maj_int_min[dataset_name])\n",
    "    elif resample=='spider':\n",
    "        cost = np.ones((no_classes, no_classes))\n",
    "        np.fill_diagonal(cost, 0)\n",
    "        clf = SPIDER3(k=5, cost=cost, majority_classes=maj_int_min[dataset_name]['maj'], intermediate_classes=maj_int_min[dataset_name]['int'], minority_classes=maj_int_min[dataset_name]['min'])\n",
    "        X_train_resampled, y_train_resampled = clf.fit_transform(X_train.astype(np.float64), y_train)\n",
    "    elif 'soupbg' in resample or 'mrbbag' in resample:\n",
    "        # SOUP Bagging does it by itself\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    else:\n",
    "        raise ValueError(f'Bad type{resample}')\n",
    "    return X_train_resampled, y_train_resampled\n",
    "\n",
    "\n",
    "\n",
    "def test_resampling(res, dataset_values, dataset_name):\n",
    "    X, y = dataset_values.data, dataset_values.target\n",
    "\n",
    "    no_classes = np.unique(y).size\n",
    "    minority_class = maj_int_min[dataset_name]['min']\n",
    "    result_data = defaultdict(int)\n",
    "    run_data = defaultdict(lambda: defaultdict(list)) # {metric: {run_number: [scores]}}\n",
    "    for i in range(10):\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True,random_state=i)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            normalizer = StandardScaler().fit(X_train)\n",
    "\n",
    "            X_train = normalizer.transform(X_train)\n",
    "            X_test = normalizer.transform(X_test)\n",
    "            X_train_resampled, y_train_resampled = resample_data(res, i, X_train, y_train, no_classes, dataset_name)\n",
    "\n",
    "            # for clf_name in ['knn']:\n",
    "            for clf_name in ['knn','tree']:\n",
    "                if clf_name == 'knn':\n",
    "                    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "                elif clf_name == 'tree':\n",
    "                    clf = DecisionTreeClassifier(random_state=i)\n",
    "                # DONT JUDGE ME\n",
    "                if res == 'soupbg005':\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=5)\n",
    "                    clf = vote_classifier\n",
    "                elif res == 'soupbg015':\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=15)\n",
    "                    clf = vote_classifier\n",
    "                elif res == 'soupbg030':\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=30)\n",
    "                    clf = vote_classifier\n",
    "                elif res == 'soupbg050':\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=50)\n",
    "                    clf = vote_classifier\n",
    "                elif res == 'soupbg100':\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=100)\n",
    "                    clf = vote_classifier\n",
    "                # elif res == 'mrbbag005':\n",
    "                    \n",
    "                    \n",
    "                clf.fit(X_train_resampled, y_train_resampled)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, correction=0.001)a\n",
    "                minority_gmean = geometric_mean_score(y_test, y_pred,labels=minority_class, correction=0.001)\n",
    "                avg_acc = np.mean(recall_score(y_test, y_pred, average=None))\n",
    "                run_data['g_mean_{}'.format(clf_name)][str(i)].append(gmean)\n",
    "                run_data['g_mean_{}_minority'.format(clf_name)][str(i)].append(minority_gmean)\n",
    "                # run_data['avg_acc_{}'.format(clf_name)][str(i)].append(avg_acc)\n",
    "    \n",
    "    def get_score_from_metric(run_data, metric):\n",
    "        runs = run_data[metric]\n",
    "        runs_scores_list = list(runs.values()) #[[one run k-foledscores],[..]]\n",
    "        result = np.mean(list(map(np.mean, runs_scores_list)))\n",
    "        return result\n",
    "            \n",
    "    for metric_name, metric_values in run_data.items():\n",
    "        result_data[metric_name] = get_score_from_metric(run_data, metric_name)\n",
    "        \n",
    "    return result_data\n",
    "\n",
    "\n",
    "def provide_test_and_get_scores(dataset, clf_res):\n",
    "    scores = defaultdict(lambda: defaultdict(dict))\n",
    "    for dataset_name, dataset_values in tqdm_notebook(datasets.items(),total=len(datasets), desc='1st loop'):\n",
    "        for resample in clf_res_names:\n",
    "            result_data = test_resampling(resample, dataset_values, dataset_name)\n",
    "            for key in result_data:\n",
    "                scores[key][dataset_name][resample] = round(result_data[key],4)\n",
    "    return scores\n",
    "\n",
    "clf_res_names =['soupbg005','soupbg015', 'soupbg030', 'soupbg050', 'soupbg100']\n",
    "datasets = load_arff_datasets()\n",
    "scores = provide_test_and_get_scores(datasets, clf_res_names)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wszystkie zbiory danych:\n",
    "#### Drzewo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_tree'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### kNN - 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_knn'])\n",
    "# print_scores(avg_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rzeczywiste zbiory danych\n",
    "#### Drzewo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_tree'],only_read_dt=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### kNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_knn'],only_read_dt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wyniki dla klas mniejszościowych\n",
    "\n",
    "### Wszystkie zbiory danych:\n",
    "#### Drzewo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_tree_minority'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### kNN - 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_knn_minority'])\n",
    "# print_scores(avg_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Porównanie baggingów - głosowanie przez średnią"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clf_res_names =['base','soup','soupbg005','soupbg015','soupbg030', 'soupbg050', 'soupbg100']\n",
    "# # clf_res_names =['base','global','smote','mdo','soup']\n",
    "# # clf_res_names =['base','global','soup']\n",
    "# # datasets = load_arff_datasets()\n",
    "# scores = provide_test_and_get_scores(datasets, clf_res_names)\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wszystkie zbiory danych:\n",
    "#### Drzewo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print_scores(scores['g_mean_tree'])\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### kNN - 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print_scores(scores['g_mean_knn'])\n",
    "# # print_scores(avg_acc)\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# print_scores(scores['g_mean_knn'])\n",
    "# # print_scores(avg_acc)\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_scores(scores['g_mean_knn_minority'])\n",
    "# print_scores(avg_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Porównanie baggingów - głosowanie przez średnią"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clf_res_names =['base','soup','soupbg005','soupbg015','soupbg030', 'soupbg050', 'soupbg100']\n",
    "# # clf_res_names =['base','global','smote','mdo','soup']\n",
    "# # clf_res_names =['base','global','soup']\n",
    "# # datasets = load_arff_datasets()\n",
    "# scores = provide_test_and_get_scores(datasets, clf_res_names)\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wszystkie zbiory danych:\n",
    "#### Drzewo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print_scores(scores['g_mean_tree'])\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### kNN - 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print_scores(scores['g_mean_knn'])\n",
    "# # print_scores(avg_acc)\n",
    "# \n",
    "# \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}